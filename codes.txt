#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
task.py

'from task import ...' 식으로 함수들을 불러와
특정 데이터셋에 대해 전체 COLMAP 파이프라인을 실행하는 예시.
"""

from application.exe import all_pipeline, prepare, feature_extraction, match_features, mapper, dense_reconstruction

# 샘플 입력/출력 경로 지정
input_path = "inputs/desk-images"     # 이미지를 저장한 폴더
output_path = "outputs/3dgs-images"   # COLMAP 결과 저장 폴더
USE_GPU = True
GPU_INDEX = 1 if USE_GPU else -1

# (1) 전체 파이프라인 한 번에 돌리기
# all_pipeline(input_path, output_path, GPU_INDEX)

# (2) 만약 단계별로 나누어 호출하고 싶다면 (주석 해제 후 사용)
# prepare(input_path, output_path)
# feature_extraction(output_path, GPU_INDEX)
# match_features(output_path, GPU_INDEX)
# mapper(output_path)
# dense_reconstruction(output_path, GPU_INDEX)

# ---------- (여기부터 작성) ----------

all_pipeline(input_path, output_path, GPU_INDEX)


#!/usr/bin/env python3 exe.py
# -*- coding: utf-8 -*-

import os
import subprocess
import logging
import sys

###############################################################################
# 로깅 설정
###############################################################################
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# 스트림 핸들러(콘솔/stdout) 세팅
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.DEBUG)
# 로그 포맷 지정
formatter = logging.Formatter("[%(levelname)s] %(name)s - %(message)s")
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# (선택) 파일 핸들러도 추가해 로그를 파일로 남기고 싶다면 활성화
# file_handler = logging.FileHandler("colmap_pipeline.log")
# file_handler.setLevel(logging.DEBUG)
# file_handler.setFormatter(formatter)
# logger.addHandler(file_handler)

###############################################################################
# 설정부
###############################################################################

# colmap 실행 경로(현재 디렉토리에 있는 심볼릭 링크가 '../colmap'을 가리킨다고 가정)
COLMAP_EXE = os.path.abspath("../colmap")

###############################################################################
# 유틸 함수
###############################################################################

def run_colmap(cmd_args):
    """
    COLMAP을 실행하는 헬퍼 함수.
    cmd_args는 ['feature_extractor', '--database_path', ...] 형태로 전달.
    """
    logger.debug(f"Preparing to run colmap with cmd_args: {cmd_args}")
    if not os.path.exists(COLMAP_EXE):
        logger.error(f"COLMAP executable not found: {COLMAP_EXE}")
        raise FileNotFoundError(f"COLMAP executable not found: {COLMAP_EXE}")
    
    full_cmd = [COLMAP_EXE] + cmd_args
    logger.info(f"Running: {' '.join(full_cmd)}")

    # 실제 실행
    try:
        subprocess.run(full_cmd, check=True)
        logger.debug("COLMAP command finished without errors.")
    except subprocess.CalledProcessError as e:
        logger.error(f"COLMAP command failed with exit code {e.returncode}")
        raise

def safe_makedirs(path):
    """os.makedirs를 안전하게 호출"""
    logger.debug(f"Checking if directory exists: {path}")
    if not os.path.exists(path):
        os.makedirs(path)
        logger.info(f"Created directory: {path}")
    else:
        logger.debug(f"Directory already exists: {path}")

###############################################################################
# 단계별 함수들
###############################################################################

def prepare(input_path, output_foldername):
    """
    1) 출력 폴더 생성
    2) 입력 폴더 -> 'images' 심볼릭 링크로 연결
    """
    logger.debug(f"prepare() called with input_path={input_path}, output_foldername={output_foldername}")
    input_abs = os.path.abspath(input_path)
    output_abs = os.path.abspath(output_foldername)
    
    logger.debug(f"Absolute input path: {input_abs}")
    logger.debug(f"Absolute output path: {output_abs}")
    
    safe_makedirs(output_abs)
    
    images_link = os.path.join(output_abs, "images")
    logger.debug(f"Checking symlink for images: {images_link}")
    
    if not os.path.islink(images_link):
        rel_target = os.path.relpath(input_abs, os.path.dirname(images_link))
        logger.debug(f"Creating symlink from {images_link} to {rel_target}")
        os.symlink(rel_target, images_link)
        logger.info(f"Created symlink: {images_link} -> {rel_target}")
    else:
        logger.debug(f"Symlink already exists: {images_link}, skipping creation.")

def feature_extraction(output_foldername, gpu_index=0):
    """
    SIFT 특징점 추출
    - 데이터베이스 파일: outputs/<folder>/database.db
    - 이미지 경로: outputs/<folder>/images
    - gpu_index: GPU 인덱스 (-1: CPU 사용)
    """
    logger.debug(f"feature_extraction() called with output_foldername={output_foldername}, gpu_index={gpu_index}")
    output_abs = os.path.abspath(output_foldername)
    db_path = os.path.join(output_abs, "database.db")
    images_path = os.path.join(output_abs, "images")
    
    cmd = [
        "feature_extractor",
        "--database_path", db_path,
        "--image_path", images_path,
        "--SiftExtraction.use_gpu", "1" if gpu_index >= 0 else "0"
    ]
    
    run_colmap(cmd)

def match_features(output_foldername, gpu_index=0):
    """
    특징점 매칭 (exhaustive_matcher)
    - 데이터베이스 파일: outputs/<folder>/database.db
    - gpu_index: GPU 인덱스 (-1: CPU 사용)
    """
    logger.debug(f"match_features() called with output_foldername={output_foldername}, gpu_index={gpu_index}")
    output_abs = os.path.abspath(output_foldername)
    db_path = os.path.join(output_abs, "database.db")
    
    cmd = [
        "exhaustive_matcher",
        "--database_path", db_path,
        "--SiftMatching.use_gpu", "1" if gpu_index >= 0 else "0"
    ]
    
    run_colmap(cmd)

def mapper(output_foldername):
    """
    Sparse Reconstruction
    - outputs/<folder>/database.db, images -> outputs/<folder>/sparse 폴더
    """
    logger.debug(f"mapper() called with output_foldername={output_foldername}")
    output_abs = os.path.abspath(output_foldername)
    db_path = os.path.join(output_abs, "database.db")
    images_path = os.path.join(output_abs, "images")
    sparse_folder = os.path.join(output_abs, "sparse")
    
    logger.debug(f"Output for sparse reconstruction: {sparse_folder}")
    safe_makedirs(sparse_folder)
    
    cmd = [
        "mapper",
        "--database_path", db_path,
        "--image_path", images_path,
        "--output_path", sparse_folder
    ]
    
    logger.debug(f"Mapper command arguments: {cmd}")
    run_colmap(cmd)

def dense_reconstruction(output_foldername, gpu_index=0):
    """
    Dense Reconstruction (image_undistorter -> patch_match_stereo -> stereo_fusion)
    - input: sparse/0 폴더
    - output: dense 폴더
    - gpu_index: GPU index to use for patch_match_stereo (default: 0)
    """
    logger.debug(f"dense_reconstruction() called with output_foldername={output_foldername}, gpu_index={gpu_index}")
    output_abs = os.path.abspath(output_foldername)
    sparse_folder = os.path.join(output_abs, "sparse", "0")  # mapper 기본 출력 경로
    dense_folder = os.path.join(output_abs, "dense")
    images_path = os.path.join(output_abs, "images")
    
    logger.debug(f"Sparse folder for dense: {sparse_folder}")
    logger.debug(f"Output dense folder: {dense_folder}")
    safe_makedirs(dense_folder)
    
    # 1) image_undistorter
    cmd_undist = [
        "image_undistorter",
        "--image_path", images_path,
        "--input_path", sparse_folder,
        "--output_path", dense_folder,
        "--output_type", "COLMAP"
    ]
    logger.debug(f"image_undistorter command: {cmd_undist}")
    run_colmap(cmd_undist)
    
    # 2) patch_match_stereo
    cmd_patch = [
        "patch_match_stereo",
        "--workspace_path", dense_folder,
        "--workspace_format", "COLMAP",
        "--PatchMatchStereo.gpu_index", str(gpu_index)
    ]
    
    logger.debug(f"Running patch_match_stereo with GPU index {gpu_index}")
    run_colmap(cmd_patch)
    
    # 3) stereo_fusion
    fused_ply = os.path.join(dense_folder, "fused.ply")
    cmd_fusion = [
        "stereo_fusion",
        "--workspace_path", dense_folder,
        "--workspace_format", "COLMAP",
        "--input_type", "geometric",
        "--output_path", fused_ply
    ]
    logger.debug(f"stereo_fusion command: {cmd_fusion}")
    run_colmap(cmd_fusion)

def all_pipeline(input_path, output_foldername, gpu_index=0):
    """
    prepare -> feature_extraction -> match_features -> mapper -> dense_reconstruction
    전체 프로세스를 한 번에 돌리는 편의 함수

    Args:
        input_path: 입력 이미지 폴더 경로
        output_foldername: 출력 폴더 경로
        gpu_index: GPU 인덱스 (기본값: 0, -1: CPU 사용)
    """
    logger.info("=== Starting ALL PIPELINE ===")
    logger.debug(f"all_pipeline called with input_path={input_path}, output_foldername={output_foldername}, gpu_index={gpu_index}")
    prepare(input_path, output_foldername)
    feature_extraction(output_foldername, gpu_index)
    match_features(output_foldername, gpu_index)
    mapper(output_foldername)
    dense_reconstruction(output_foldername, gpu_index)
    logger.info("=== All steps completed ===")


###############################################################################
# 사용 예시 (직접 실행 시)
###############################################################################
if __name__ == "__main__":
    """
    아래 코드는 예시로, 전체 파이프라인을 한 번에 실행해보고 싶다면:
    all_pipeline("inputs/datasetA", "outputs/datasetA", gpu_index=0)  # 첫 번째 GPU 사용

    실제 환경에서는 import 후
    all_pipeline(...) 등 원하는 함수를 호출하세요.
    """
    # 예) 아래 주석 해제 후 테스트:
    # all_pipeline("inputs/datasetA", "outputs/datasetA", gpu_index=1)  # 두 번째 GPU 사용
    pass
